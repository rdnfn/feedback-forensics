{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset operations üóÇÔ∏è\n",
    "\n",
    "This guide covers how to work with AnnotatedPairs datasets using Feedback Forensics' dataset operations tools.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Feedback Forensics provides both CLI and Python API tools for manipulating AnnotatedPairs datasets. This is useful for:\n",
    "\n",
    "- **Converting CSV data**: Transform preference data from CSV to AnnotatedPairs for use in Feedback Forensics\n",
    "- **Merging datasets**: Combine multiple annotated datasets with overlapping comparisons\n",
    "- **Data restoration**: Merge annotation-only datasets with full comparison data\n",
    "\n",
    "## Command Line Interface\n",
    "\n",
    "For quick dataset operations, use the `ff-data` CLI tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: ff-data [-h] {merge,csv_to_ap} ...\n",
      "\n",
      "Swiss army knife for AnnotatedPairs datasets\n",
      "\n",
      "positional arguments:\n",
      "  {merge,csv_to_ap}  Available commands\n",
      "    merge            Merge two AnnotatedPairs datasets\n",
      "    csv_to_ap        Convert CSV to AnnotatedPairs format\n",
      "\n",
      "options:\n",
      "  -h, --help         show this help message and exit\n"
     ]
    }
   ],
   "source": [
    "!ff-data --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting CSV to AnnotatedPairs\n",
    "\n",
    "Before you can use datasets with Feedback Forensics, they need to be in the AnnotatedPairs format. If you have a raw CSV file with preference data, you can convert it using the `csv_to_ap` command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: ff-data csv_to_ap [-h] --name NAME csv_file output\n",
      "\n",
      "positional arguments:\n",
      "  csv_file     Input CSV file with columns text_a, text_b, preferred_text\n",
      "  output       Output AnnotatedPairs JSON file (use \"-\" for stdout)\n",
      "\n",
      "options:\n",
      "  -h, --help   show this help message and exit\n",
      "  --name NAME  Dataset name for the AnnotatedPairs output\n"
     ]
    }
   ],
   "source": [
    "!ff-data csv_to_ap --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your CSV file must contain the required columns:\n",
    "- `text_a`, `text_b`: The two responses being compared\n",
    "- `preferred_text`: Which response was preferred (`\"text_a\"` or `\"text_b\"`)\n",
    "\n",
    "Optional columns:\n",
    "- `input` or `prompt`: The prompt that generated the responses\n",
    "- `model_a`, `model_b`: Names of the models that generated the responses\n",
    "\n",
    "Here's an example converting the sample data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "scroll-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìú  | INFO | Converting CSV to AnnotatedPairs: ../../data/input/example.csv\u001b[0m\n",
      "/home/vscode/.local/lib/python3.10/site-packages/inverse_cai/data/annotated_pairs_format.py:264: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(str)  # ensure all columns are hashable\n",
      "üìú  | INFO | Available metadata columns: ['index']\u001b[0m\n",
      "üìú  | INFO | Outputting AnnotatedPairs dataset to stdout\u001b[0m\n",
      "{\n",
      "  \"metadata\": {\n",
      "    \"version\": \"2.0\",\n",
      "    \"description\": \"Annotated pairs dataset with annotations from ICAI\",\n",
      "    \"created_at\": \"2025-05-30T16:49:16Z\",\n",
      "    \"dataset_name\": \"Example Dataset\",\n",
      "    \"default_annotator\": \"ba751e7b\",\n",
      "    \"available_metadata_keys_per_comparison\": [\n",
      "      \"index\"\n",
      "    ]\n",
      "  },\n",
      "  \"annotators\": {\n",
      "    \"ba751e7b\": {\n",
      "      \"name\": \"preferred_text\",\n",
      "      \"description\": \"Default annotator from original dataset (from column `preferred_text`)\",\n",
      "      \"type\": \"unknown\"\n",
      "    }\n",
      "  },\n",
      "  \"comparisons\": [\n",
      "    {\n",
      "      \"id\": \"a4e9e77e\",\n",
      "      \"prompt\": null,\n",
      "      \"response_a\": {\n",
      "        \"text\": \"In the heart of a bustling city, a sleek black cat named Shadow prowled the moonlit rooftops, her eyes gleaming with curiosity and mischief. She discovered a hidden garden atop an old apartment building, where she danced under the stars, chasing fireflies that glowed like tiny lanterns. As dawn painted the sky in hues of orange and pink, Shadow found her way back home, carrying the secret of the garden in her heart.\"\n",
      "      },\n",
      "      \"response_b\": {\n",
      "        \"text\": \"Across the town, in a cozy neighborhood, a golden retriever named Buddy embarked on his daily adventure, tail wagging with uncontainable excitement. He found a lost toy under the bushes in the park, its colors faded and fabric worn, but to Buddy, it was a treasure untold. Returning home with his newfound prize, Buddy's joyful barks filled the air, reminding everyone in the house that happiness can be found in the simplest of things.\"\n",
      "      },\n",
      "      \"annotations\": {\n",
      "        \"ba751e7b\": {\n",
      "          \"pref\": \"a\"\n",
      "        }\n",
      "      },\n",
      "      \"metadata\": {\n",
      "        \"index\": \"0\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "üìú  | INFO | Successfully converted CSV to AnnotatedPairs\u001b[0m\n",
      "üìú  | INFO | Result contains 1 comparisons and 1 annotators\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!ff-data csv_to_ap ../../data/input/example.csv - --name \"Example Dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a basic AnnotatedPairs dataset with just the original preferences from your CSV file. **Note: This converted dataset will not include principle-based annotations** - it only contains the original preference data.\n",
    "\n",
    "To get rich principle-based annotations that enable personality trait analysis, you should use `ff-annotate` (requiring API keys) instead:\n",
    "\n",
    "```bash\n",
    "ff-annotate --datapath=\"../../data/input/example.csv\"\n",
    "```\n",
    "\n",
    "The `csv_to_ap` command is useful for quick conversion when you want to merge a CSV dataset with annotations in annotated pairs format or when you want to work with just the original preference data without additional AI annotations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging datasets via CLI\n",
    "\n",
    "`ff-data` can merge multiple datasets with possibly overlapping comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: ff-data merge [-h] [--name NAME] [--desc DESC] first second output\n",
      "\n",
      "positional arguments:\n",
      "  first        First dataset file (takes precedence in conflicts)\n",
      "  second       Second dataset file\n",
      "  output       Output file (use \"-\" for stdout)\n",
      "\n",
      "options:\n",
      "  -h, --help   show this help message and exit\n",
      "  --name NAME  Override dataset name for merged result\n",
      "  --desc DESC  Override description for merged result\n"
     ]
    }
   ],
   "source": [
    "!ff-data merge --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example usage, merging identical datasets and printing the merged dataset to stdout for demonstration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "scroll-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìú  | INFO | Merging AnnotatedPairs: ../../data/output/annotated_pairs.json + ../../data/output/annotated_pairs.json\u001b[0m\n",
      "üìú  | INFO | Merging AnnotatedPairs datasets\u001b[0m\n",
      "üìú  | INFO | First dataset: 1 comparisons, 41 annotators\u001b[0m\n",
      "üìú  | INFO | Second dataset: 1 comparisons, 41 annotators\u001b[0m\n",
      "üìú  | INFO | Found 1 matching comparisons, 0 unique to first, 0 unique to second\u001b[0m\n",
      "üìú  | INFO | Merged result: 1 comparisons, 41 annotators\u001b[0m\n",
      "üìú  | INFO | Outputting merged dataset to stdout\u001b[0m\n",
      "{\n",
      "  \"metadata\": {\n",
      "    \"version\": \"2.0\",\n",
      "    \"created_at\": \"2025-05-30T15:36:36Z\",\n",
      "    \"dataset_name\": \"ICAI Training Dataset - 2025-05-07_18-35-25\",\n",
      "    \"description\": \"AnnotatedPairs dataset with annotations from ICAI\",\n",
      "    \"default_annotator\": \"ba751e7b\",\n",
      "    \"available_metadata_keys_per_comparison\": [\n",
      "      \"index\"\n",
      "    ]\n",
      "  },\n",
      "  \"annotators\": {\n",
      "    \"ba751e7b\": {\n",
      "      \"name\": \"preferred_text\",\n",
      "      \"description\": \"Default annotator from original dataset (from column `preferred_text`)\",\n",
      "      \"type\": \"unknown\"\n",
      "    },\n",
      "    \"bf731c7f\": {\n",
      "      \"description\": \"Select the response that is more concise\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"d4f11654\": {\n",
      "      \"description\": \"Select the response that is too long\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"11bb8171\": {\n",
      "      \"description\": \"Select the response that is more verbose\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"29dbae6e\": {\n",
      "      \"description\": \"Select the response that provides a numbered list format\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"2dbc7bd4\": {\n",
      "      \"description\": \"Select the response that has more structured formatting\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"e50b5135\": {\n",
      "      \"description\": \"Select the response that ends with a follow-up question\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"4970587c\": {\n",
      "      \"description\": \"Select the response that more directly follows instructions\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"75cfba3f\": {\n",
      "      \"description\": \"Select the response that more strictly follows the requested format\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"2e2d4304\": {\n",
      "      \"description\": \"Select the response that is more polite\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"051d9a8c\": {\n",
      "      \"description\": \"Select the response that has a more friendly tone\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"336abb5b\": {\n",
      "      \"description\": \"Select the response that uses more casual language\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"d7a9e296\": {\n",
      "      \"description\": \"Select the response that uses more formal language\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"8d63fe06\": {\n",
      "      \"description\": \"Select the response that provides more detailed explanations\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"65f09d33\": {\n",
      "      \"description\": \"Select the response that includes inappropriate language\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"2a9c2ec5\": {\n",
      "      \"description\": \"Select the response that suggests illegal activities\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"e14e5dbe\": {\n",
      "      \"description\": \"Select the response that has a more avoidant tone\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"03912bdb\": {\n",
      "      \"description\": \"Select the response that is less complex\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"187a0209\": {\n",
      "      \"description\": \"Select the response that is more factually correct\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"73622a5c\": {\n",
      "      \"description\": \"Select the response that follows best practices\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"0d30c700\": {\n",
      "      \"description\": \"Select the response that is more offensive\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"bab684e8\": {\n",
      "      \"description\": \"Select the response that includes more references to other sources\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"c5d6e5ef\": {\n",
      "      \"description\": \"Select the response that expresses more emotion\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"06c45eb6\": {\n",
      "      \"description\": \"Select the response that contains less harmful information\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"cceeacb8\": {\n",
      "      \"description\": \"Select the response that refuses to answer the question\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"b6af059c\": {\n",
      "      \"description\": \"Select the response that uses more bold and italics text\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"03de9971\": {\n",
      "      \"description\": \"Select the response that provides more examples\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"00587da7\": {\n",
      "      \"description\": \"Select the response that uses more humour\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"3d478ab7\": {\n",
      "      \"description\": \"Select the response that uses more personal pronouns (I, we, you)\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"914a240e\": {\n",
      "      \"description\": \"Select the response that includes more ethical considerations\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"dc31b93e\": {\n",
      "      \"description\": \"Select the response that acknowledges own limitations or uncertainty more\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"cd26499c\": {\n",
      "      \"description\": \"Select the response that is more creative and original\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"3bbb1c19\": {\n",
      "      \"description\": \"Select the response that makes more confident statements\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"678d6402\": {\n",
      "      \"description\": \"Select the response that provides clearer reasoning with well-supported arguments\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"2962f600\": {\n",
      "      \"description\": \"Select the response that provides conclusions without full reasoning\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"e7770f1a\": {\n",
      "      \"description\": \"Select the response that actively engages the reader with rhetorical questions\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"f25f77ff\": {\n",
      "      \"description\": \"Select the response that is more vague\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"19df27fc\": {\n",
      "      \"description\": \"Select the response that uses a more enthusiastic tone\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"4e98e7d2\": {\n",
      "      \"description\": \"Select the response that contains more concise straightforward solution steps\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"39f3d2e7\": {\n",
      "      \"description\": \"Select the response that avoids unnecessary repetition\",\n",
      "      \"type\": \"principle\"\n",
      "    },\n",
      "    \"b09dbe40\": {\n",
      "      \"description\": \"Select the response that uses more mathematical symbols and notation\",\n",
      "      \"type\": \"principle\"\n",
      "    }\n",
      "  },\n",
      "  \"comparisons\": [\n",
      "    {\n",
      "      \"id\": \"a4e9e77e\",\n",
      "      \"response_a\": {\n",
      "        \"text\": \"In the heart of a bustling city, a sleek black cat named Shadow prowled the moonlit rooftops, her eyes gleaming with curiosity and mischief. She discovered a hidden garden atop an old apartment building, where she danced under the stars, chasing fireflies that glowed like tiny lanterns. As dawn painted the sky in hues of orange and pink, Shadow found her way back home, carrying the secret of the garden in her heart.\"\n",
      "      },\n",
      "      \"response_b\": {\n",
      "        \"text\": \"Across the town, in a cozy neighborhood, a golden retriever named Buddy embarked on his daily adventure, tail wagging with uncontainable excitement. He found a lost toy under the bushes in the park, its colors faded and fabric worn, but to Buddy, it was a treasure untold. Returning home with his newfound prize, Buddy's joyful barks filled the air, reminding everyone in the house that happiness can be found in the simplest of things.\"\n",
      "      },\n",
      "      \"annotations\": {\n",
      "        \"ba751e7b\": {\n",
      "          \"pref\": \"a\"\n",
      "        },\n",
      "        \"bf731c7f\": {\n",
      "          \"pref\": \"b\"\n",
      "        },\n",
      "        \"d4f11654\": {\n",
      "          \"pref\": \"a\"\n",
      "        },\n",
      "        \"11bb8171\": {\n",
      "          \"pref\": \"a\"\n",
      "        },\n",
      "        \"29dbae6e\": {\n",
      "          \"pref\": null,\n",
      "          \"no_pref_reason\": \"not_applicable\"\n",
      "        },\n",
      "        \"2dbc7bd4\": {\n",
      "          \"pref\": null,\n",
      "          \"no_pref_reason\": \"not_applicable\"\n",
      "        },\n",
      "        \"e50b5135\": {\n",
      "          \"pref\": null,\n",
      "          \"no_pref_reason\": \"not_applicable\"\n",
      "        },\n",
      "        \"4970587c\": {\n",
      "          \"pref\": null,\n",
      "          \"no_pref_reason\": \"not_applicable\"\n",
      "        },\n",
      "        \"75cfba3f\": {\n",
      "          \"pref\": null,\n",
      "          \"no_pref_reason\": \"not_applicable\"\n",
      "        },\n",
      "        \"2e2d4304\": {\n",
      "          \"pref\": null,\n",
      "          \"no_pref_reason\": \"not_applicable\"\n",
      "        },\n",
      "        \"051d9a8c\": {\n",
      "          \"pref\": \"b\"\n",
      "        },\n",
      "        \"336abb5b\": {\n",
      "          \"pref\": \"b\"\n",
      "        },\n",
      "        \"d7a9e296\": {\n",
      "          \"pref\": null,\n",
      "          \"no_pref_reason\": \"not_applicable\"\n",
      "        },\n",
      "        \"8d63fe06\": {\n",
      "          \"pref\": \"a\"\n",
      "        },\n",
      "        \"65f09d33\": {\n",
      "          \"pref\": null,\n",
      "          \"no_pref_reason\": \"not_applicable\"\n",
      "        },\n",
      "        \"2a9c2ec5\": {\n",
      "          \"pref\": null,\n",
      "          \"no_pref_reason\": \"not_applicable\"\n",
      "        },\n",
      "        \"e14e5dbe\": {\n",
      "          \"pref\": null,\n",
      "          \"no_pref_reason\": \"not_applicable\"\n",
      "        },\n",
      "        \"03912bdb\": {\n",
      "          \"pref\": \"b\"\n",
      "        },\n",
      "        \"187a0209\": {\n",
      "          \"pref\": null,\n",
      "          \"no_pref_reason\": \"not_applicable\"\n",
      "        },\n",
      "        \"73622a5c\": {\n",
      "          \"pref\": null,\n",
      "          \"no_pref_reason\": \"not_applicable\"\n",
      "        },\n",
      "        \"0d30c700\": {\n",
      "          \"pref\": null,\n",
      "          \"no_pref_reason\": \"not_applicable\"\n",
      "        },\n",
      "        \"bab684e8\": {\n",
      "          \"pref\": null,\n",
      "          \"no_pref_reason\": \"not_applicable\"\n",
      "        },\n",
      "        \"c5d6e5ef\": {\n",
      "          \"pref\": \"a\"\n",
      "        },\n",
      "        \"06c45eb6\": {\n",
      "          \"pref\": null,\n",
      "          \"no_pref_reason\": \"not_applicable\"\n",
      "        },\n",
      "        \"cceeacb8\": {\n",
      "          \"pref\": null,\n",
      "          \"no_pref_reason\": \"not_applicable\"\n",
      "        },\n",
      "        \"b6af059c\": {\n",
      "          \"pref\": null,\n",
      "          \"no_pref_reason\": \"not_applicable\"\n",
      "        },\n",
      "        \"03de9971\": {\n",
      "          \"pref\": null,\n",
      "          \"no_pref_reason\": \"not_applicable\"\n",
      "        },\n",
      "        \"00587da7\": {\n",
      "          \"pref\": null,\n",
      "          \"no_pref_reason\": \"not_applicable\"\n",
      "        },\n",
      "        \"3d478ab7\": {\n",
      "          \"pref\": null,\n",
      "          \"no_pref_reason\": \"not_applicable\"\n",
      "        },\n",
      "        \"914a240e\": {\n",
      "          \"pref\": null,\n",
      "          \"no_pref_reason\": \"not_applicable\"\n",
      "        },\n",
      "        \"dc31b93e\": {\n",
      "          \"pref\": null,\n",
      "          \"no_pref_reason\": \"not_applicable\"\n",
      "        },\n",
      "        \"cd26499c\": {\n",
      "          \"pref\": \"a\"\n",
      "        },\n",
      "        \"3bbb1c19\": {\n",
      "          \"pref\": null,\n",
      "          \"no_pref_reason\": \"not_applicable\"\n",
      "        },\n",
      "        \"678d6402\": {\n",
      "          \"pref\": null,\n",
      "          \"no_pref_reason\": \"not_applicable\"\n",
      "        },\n",
      "        \"2962f600\": {\n",
      "          \"pref\": null,\n",
      "          \"no_pref_reason\": \"not_applicable\"\n",
      "        },\n",
      "        \"e7770f1a\": {\n",
      "          \"pref\": null,\n",
      "          \"no_pref_reason\": \"not_applicable\"\n",
      "        },\n",
      "        \"f25f77ff\": {\n",
      "          \"pref\": null,\n",
      "          \"no_pref_reason\": \"not_applicable\"\n",
      "        },\n",
      "        \"19df27fc\": {\n",
      "          \"pref\": \"b\"\n",
      "        },\n",
      "        \"4e98e7d2\": {\n",
      "          \"pref\": null,\n",
      "          \"no_pref_reason\": \"not_applicable\"\n",
      "        },\n",
      "        \"39f3d2e7\": {\n",
      "          \"pref\": null,\n",
      "          \"no_pref_reason\": \"not_applicable\"\n",
      "        },\n",
      "        \"b09dbe40\": {\n",
      "          \"pref\": null,\n",
      "          \"no_pref_reason\": \"not_applicable\"\n",
      "        }\n",
      "      },\n",
      "      \"metadata\": {\n",
      "        \"index\": \"0\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "üìú  | INFO | Successfully merged datasets to -\u001b[0m\n",
      "üìú  | INFO | Result contains 1 comparisons and 41 annotators\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!ff-data merge ../../data/output/annotated_pairs.json ../../data/output/annotated_pairs.json -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python API\n",
    "\n",
    "The dataset operations are also available through the `feedback_forensics.data.operations` module:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting CSV to AnnotatedPairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìú  | INFO | Available metadata columns: ['index']\u001b[0m\n",
      "Converted dataset contains 1 comparisons\n",
      "Dataset contains 1 annotators\n",
      "Note: This dataset only contains original preferences, not principle-based annotations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/inverse_cai/data/annotated_pairs_format.py:264: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(str)  # ensure all columns are hashable\n"
     ]
    }
   ],
   "source": [
    "from feedback_forensics.data.operations import csv_to_ap, save_ap\n",
    "\n",
    "# Convert CSV to AnnotatedPairs format (without principle annotations)\n",
    "ap_data = csv_to_ap(\"../../data/input/example.csv\", \"Example Dataset\")\n",
    "\n",
    "print(f\"Converted dataset contains {len(ap_data['comparisons'])} comparisons\")\n",
    "print(f\"Dataset contains {len(ap_data['annotators'])} annotators\")\n",
    "print(\"Note: This dataset only contains original preferences, not principle-based annotations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading, Merging, and Saving Datasets\n",
    "\n",
    "Merge two datasets with conflict resolution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 1 comparisons\n",
      "Dataset contains 41 annotators\n",
      "üìú  | INFO | Merging AnnotatedPairs datasets\u001b[0m\n",
      "üìú  | INFO | First dataset: 1 comparisons, 41 annotators\u001b[0m\n",
      "üìú  | INFO | Second dataset: 1 comparisons, 41 annotators\u001b[0m\n",
      "üìú  | INFO | Found 1 matching comparisons, 0 unique to first, 0 unique to second\u001b[0m\n",
      "üìú  | INFO | Merged result: 1 comparisons, 41 annotators\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from feedback_forensics.data.operations import load_ap, merge_ap\n",
    "\n",
    "# Load two datasets. Here we use the same sample data for both, but in practice you would load two different datasets.\n",
    "dataset1 = load_ap(\"../../data/output/annotated_pairs.json\")\n",
    "dataset2 = load_ap(\"../../data/output/annotated_pairs.json\")\n",
    "\n",
    "print(f\"Dataset contains {len(dataset1['comparisons'])} comparisons\")\n",
    "print(f\"Dataset contains {len(dataset1['annotators'])} annotators\")\n",
    "\n",
    "# Merge them (first dataset takes precedence in conflicts). In this case, the datasets are identical.\n",
    "merged_dataset = merge_ap(dataset1, dataset2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can save the resulting dataset to a file:\n",
    "\n",
    "```python\n",
    "save_ap(merged_dataset, \"merged_dataset.json\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Merging Works\n",
    "\n",
    "The merge operation works as follows:\n",
    "\n",
    "1. **Comparison Matching**: Uses content-based hash IDs to identify identical comparisons\n",
    "2. **Annotation Combining**: Merges all annotations from both datasets for matching comparisons\n",
    "3. **Conflict Resolution**: When conflicts occur, the first dataset takes precedence (with warnings logged)\n",
    "\n",
    "This is particularly useful for restoring datasets where you have:\n",
    "- One dataset with full comparison data but limited annotations\n",
    "- Another dataset with rich annotations but possibly missing comparison details\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- [Analyze your merged datasets](../guide/feedback.ipynb)\n",
    "- [API Reference](../api.ipynb)\n",
    "- [Learn about the underlying method](../method/index.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
