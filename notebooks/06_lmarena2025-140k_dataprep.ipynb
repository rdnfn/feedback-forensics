{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7371be14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "def process_data(\n",
    "        hf_path: str = \"lmarena-ai/arena-human-preference-140k\",\n",
    "        remove_token_counts: bool = True,\n",
    "        max_conv_char_length: int = 5000,\n",
    "        sample_size: int = 10000,\n",
    "        seed: int = 42,\n",
    "        ):\n",
    "\n",
    "    dataset = datasets.load_dataset(hf_path)\n",
    "    df = dataset[\"train\"].to_pandas()\n",
    "\n",
    "    ### Data subset selection\n",
    "    print(f\"Loading {hf_path} dataset\")\n",
    "    print(f\"Dataset original size: {len(df)}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # limit to non-tie votes\n",
    "    df = df[df[\"winner\"].isin([\"model_a\", \"model_b\"])]\n",
    "    print(f\"Dataset size after filtering to non-tie votes: {len(df)}\")\n",
    "    # limit to English-language conversations\n",
    "    df = df[df[\"language\"] == \"en\"]\n",
    "    print(f\"Dataset size after filtering language to English: {len(df)}\")\n",
    "    df[\"marked_for_deletion\"] = False\n",
    "\n",
    "\n",
    "    ### Data cleaning and preprocessing\n",
    "\n",
    "    if remove_token_counts:\n",
    "        print(\"Removing token counts from each turn\")\n",
    "        # remove token counts from each turn\n",
    "        # does not apply to lmarena-ai/arena-human-preference-140k\n",
    "        # where this information is in another column\n",
    "        def remove_token_counts(row):\n",
    "            for conversation in [\"conversation_a\", \"conversation_b\"]:\n",
    "                conv_list = row[conversation]\n",
    "                for turn in conv_list:\n",
    "                    if \"num_tokens\" in turn:\n",
    "                        turn.pop(\"num_tokens\")\n",
    "                row[conversation] = conv_list\n",
    "            return row\n",
    "\n",
    "        df = df.apply(remove_token_counts, axis=1)\n",
    "\n",
    "    def check_conversation_nonempty(row):\n",
    "        for conversation in [\"conversation_a\", \"conversation_b\"]:\n",
    "            conv_list = row[conversation]\n",
    "            for turn in conv_list:\n",
    "                content = turn.get(\"content\")\n",
    "                if isinstance(content, str):\n",
    "                    pass\n",
    "                elif isinstance(content, np.ndarray):\n",
    "                    if len(content) == 0:\n",
    "                        print(f\"Conversation {conversation} is empty ({conv_list})\")\n",
    "                        row[\"marked_for_deletion\"] = True\n",
    "                        return row\n",
    "        return row\n",
    "\n",
    "    print(\"Checking if conversations are empty\")\n",
    "    df = df.apply(check_conversation_nonempty, axis=1)\n",
    "\n",
    "    print(\"Filtering out conversations marked for deletion\")\n",
    "    df = df[~df[\"marked_for_deletion\"]]\n",
    "    print(f\"Dataset size after filtering out conversations marked for deletion: {len(df)}\")\n",
    "    df.drop(columns=[\"marked_for_deletion\"], inplace=True)\n",
    "\n",
    "    print(f\"Sampling {sample_size} conversations out of {len(df)}\")\n",
    "    df = df.sample(sample_size, random_state=seed)\n",
    "\n",
    "\n",
    "\n",
    "    def get_text(row):\n",
    "        \"\"\"Newer version of LMArena data use different format for conversations.\n",
    "\n",
    "        E.g. lmarena-ai/arena-human-preference-140k.\n",
    "        \"\"\"\n",
    "        for conversation in [\"conversation_a\", \"conversation_b\"]:\n",
    "            conv_list = row[conversation]\n",
    "            for turn in conv_list:\n",
    "                content = turn.get(\"content\")\n",
    "                if isinstance(content, str):\n",
    "                    pass\n",
    "                elif isinstance(content, np.ndarray):\n",
    "                    assert len(content) == 1, f\"Expected single turn but got multiple turns: {content}\"\n",
    "                    assert content[0][\"type\"] == \"text\", f\"Expected text turn but got {content[0]['type']}: {content[0]}\"\n",
    "                    content = content[0][\"text\"]\n",
    "                else:\n",
    "                    raise ValueError(f\"Unexpected content type: {type(content)}\")\n",
    "\n",
    "                turn[\"content\"] = content\n",
    "\n",
    "            row[conversation] = conv_list\n",
    "        return row\n",
    "\n",
    "    print(\"Extracting text from each turn\")\n",
    "    df = df.apply(get_text, axis=1)\n",
    "\n",
    "    # set max conversation length to 4000 characters\n",
    "    MAX_CONV_LENGTH = 10000 # in characters\n",
    "    def truncate_conversation(row):\n",
    "        for conversation in [\"conversation_a\", \"conversation_b\"]:\n",
    "            conv_list = row[conversation]\n",
    "            conv_str = str(conv_list)\n",
    "            if len(conv_str) > MAX_CONV_LENGTH:\n",
    "                row[conversation] = conv_str[:MAX_CONV_LENGTH] + \"... (conversation truncated)\"\n",
    "                row[f\"truncated_{conversation}\"] = True\n",
    "            else:\n",
    "                row[f\"truncated_{conversation}\"] = False\n",
    "        return row\n",
    "\n",
    "    print(f\"Truncating conversations to {max_conv_char_length} characters\")\n",
    "    df = df.apply(truncate_conversation, axis=1)\n",
    "\n",
    "    df[\"text_a\"] = df[\"conversation_a\"]\n",
    "    df[\"text_b\"] = df[\"conversation_b\"]\n",
    "    df.drop(columns=[\"conversation_a\", \"conversation_b\"], inplace=True)\n",
    "\n",
    "\n",
    "    def transform_winner(row):\n",
    "        if row[\"winner\"] == \"model_a\":\n",
    "            return \"text_a\"\n",
    "        else:\n",
    "            return \"text_b\"\n",
    "\n",
    "    print(\"Transforming winner to preferred text\")\n",
    "    df[\"preferred_text\"] = df.apply(transform_winner, axis=1)\n",
    "\n",
    "    print(\"Saving to CSV\")\n",
    "    df.to_csv(f\"../data/output/{hf_path.split('/')[-1]}_{sample_size}samples_{max_conv_char_length}chars_english.csv\", index=False)\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken: {end_time - start_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c8b10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data(\n",
    "    hf_path=\"lmarena-ai/arena-human-preference-140k\",\n",
    "    max_conv_char_length=5000,\n",
    "    sample_size=5000,\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fabc7d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
